{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing one go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system(\"rm -rf data/*\")\n",
    "\n",
    "for subset in itertools.combinations([i for i in range(10)],2):\n",
    "\n",
    "    x_train_subset = x_train[(y_train == subset[0]) | (y_train == subset[1])]\n",
    "    y_train_subset = y_train[(y_train == subset[0]) | (y_train == subset[1])]\n",
    "    y_train_subset_binary = np.where(y_train_subset == subset[0], 0, y_train_subset)\n",
    "    y_train_subset_binary = np.where(y_train_subset_binary == subset[1], 1, y_train_subset_binary)\n",
    "\n",
    "    x_test_subset = x_test[(y_test == subset[0]) | (y_test == subset[1])]\n",
    "    y_test_subset = y_test[(y_test == subset[0]) | (y_test == subset[1])]\n",
    "    y_test_subset_binary = np.where(y_test_subset == subset[0], 0, y_test_subset)\n",
    "    y_test_subset_binary = np.where(y_test_subset_binary == subset[1], 1, y_test_subset_binary)\n",
    "\n",
    "    x_train_subset = x_train_subset.reshape(x_train_subset.shape[0],784)\n",
    "    x_test_subset = x_test_subset.reshape(x_test_subset.shape[0],784)\n",
    "\n",
    "    for preprocessing_method, preprocessing_name in pre.preprocessing_methods():\n",
    "\n",
    "        if not os.path.isdir(\"data/{}\".format(preprocessing_name)):\n",
    "            print(\"making directory: data/{}\".format(preprocessing_name))\n",
    "            os.mkdir(\"data/{}\".format(preprocessing_name))\n",
    "\n",
    "        x_train_pre, x_test_pre = preprocessing_method(x_train_subset, x_test_subset,outputsize=4)\n",
    "        #normalize again\n",
    "        x_train_pre = pre.minmax_scaler(x_train_pre,min=0,max=1)\n",
    "        x_test_pre = pre.minmax_scaler(x_test_pre,min=0,max=1)\n",
    "\n",
    "        if np.any(np.isnan(x_train_pre)) or np.any(np.isnan(x_test_pre)):\n",
    "            print(\"NaN detected\",subset,preprocessing_name)\n",
    "\n",
    "        subset_name = str(subset).replace(\"(\",\"\").replace(\")\",\"\").replace(\" \",\"\")\n",
    "\n",
    "        if not os.path.isdir(\"data/{}/{}\".format(preprocessing_name,subset_name)):\n",
    "            print(\"making directory: data/{}/{}\".format(preprocessing_name,subset_name))\n",
    "            os.mkdir(\"data/{}/{}\".format(preprocessing_name,subset_name))\n",
    "\n",
    "        for type, dataset in zip([\"x_train\",\"x_test\",\"y_train\",\"y_test\",\"y_train_binary\",\"y_test_binary\"],[x_train_pre,x_test_pre,y_train_subset,y_test_subset,y_train_subset_binary,y_test_subset_binary]):\n",
    "            np.save(\"data/\"+preprocessing_name+\"/\"+str(subset_name)+\"/\"+type+\".npy\",dataset)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
