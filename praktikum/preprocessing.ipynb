{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "from myutils import Preprocessing as pre\n",
    "from myutils import Datasets as ds\n",
    "from myutils import Helpers as h\n",
    "from myutils import Complexity_Measures as cm\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "#Magic Command, so changes in myutils module are reloaded\n",
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "%aimport myutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_test, y_test = ds.ALL_NUMBERS()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AutoEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing subset: 0,1\n",
      "Metal device set to: Apple M1 Pro\n",
      "\n",
      "systemMemory: 16.00 GB\n",
      "maxCacheSize: 5.33 GB\n",
      "\n",
      "Epoch 1/2\n",
      "396/396 [==============================] - 4s 8ms/step - loss: 0.0656\n",
      "Epoch 2/2\n",
      "396/396 [==============================] - 3s 8ms/step - loss: 0.0463\n",
      "processing subset: 0,2\n",
      "Epoch 1/2\n",
      "372/372 [==============================] - 3s 8ms/step - loss: 0.0771\n",
      "Epoch 2/2\n",
      "372/372 [==============================] - 3s 8ms/step - loss: 0.0747\n",
      "processing subset: 0,3\n",
      "Epoch 1/2\n",
      "377/377 [==============================] - 3s 8ms/step - loss: 0.0731\n",
      "Epoch 2/2\n",
      "377/377 [==============================] - 3s 7ms/step - loss: 0.0702\n",
      "processing subset: 0,4\n",
      "Epoch 1/2\n",
      "368/368 [==============================] - 3s 8ms/step - loss: 0.0732\n",
      "Epoch 2/2\n",
      "368/368 [==============================] - 3s 8ms/step - loss: 0.0667\n",
      "processing subset: 0,5\n",
      "Epoch 1/2\n",
      "355/355 [==============================] - 3s 8ms/step - loss: 0.0717\n",
      "Epoch 2/2\n",
      "355/355 [==============================] - 3s 8ms/step - loss: 0.0693\n",
      "processing subset: 0,6\n",
      "Epoch 1/2\n",
      "371/371 [==============================] - 3s 8ms/step - loss: 0.0724\n",
      "Epoch 2/2\n",
      "371/371 [==============================] - 3s 8ms/step - loss: 0.0670\n",
      "processing subset: 0,7\n",
      "Epoch 1/2\n",
      "381/381 [==============================] - 3s 9ms/step - loss: 0.0711\n",
      "Epoch 2/2\n",
      "381/381 [==============================] - 3s 8ms/step - loss: 0.0614\n",
      "processing subset: 0,8\n",
      "Epoch 1/2\n",
      "368/368 [==============================] - 3s 9ms/step - loss: 0.0738\n",
      "Epoch 2/2\n",
      "368/368 [==============================] - 3s 8ms/step - loss: 0.0710\n",
      "processing subset: 0,9\n",
      "Epoch 1/2\n",
      "371/371 [==============================] - 3s 7ms/step - loss: 0.0714\n",
      "Epoch 2/2\n",
      "371/371 [==============================] - 2s 6ms/step - loss: 0.0621\n",
      "processing subset: 1,2\n",
      "Epoch 1/2\n",
      "397/397 [==============================] - 4s 9ms/step - loss: 0.0565\n",
      "Epoch 2/2\n",
      "397/397 [==============================] - 3s 8ms/step - loss: 0.0480\n",
      "processing subset: 1,3\n",
      "Epoch 1/2\n",
      "403/403 [==============================] - 4s 8ms/step - loss: 0.0534\n",
      "Epoch 2/2\n",
      "403/403 [==============================] - 3s 8ms/step - loss: 0.0450\n",
      "processing subset: 1,4\n",
      "Epoch 1/2\n",
      "394/394 [==============================] - 3s 8ms/step - loss: 0.0525\n",
      "Epoch 2/2\n",
      "394/394 [==============================] - 3s 8ms/step - loss: 0.0437\n",
      "processing subset: 1,5\n",
      "Epoch 1/2\n",
      "381/381 [==============================] - 3s 8ms/step - loss: 0.0531\n",
      "Epoch 2/2\n",
      "381/381 [==============================] - 3s 8ms/step - loss: 0.0461\n",
      "processing subset: 1,6\n",
      "Epoch 1/2\n",
      "396/396 [==============================] - 4s 8ms/step - loss: 0.0539\n",
      "Epoch 2/2\n",
      "396/396 [==============================] - 3s 8ms/step - loss: 0.0442\n",
      "processing subset: 1,7\n",
      "Epoch 1/2\n",
      "407/407 [==============================] - 4s 8ms/step - loss: 0.0498\n",
      "Epoch 2/2\n",
      "407/407 [==============================] - 3s 8ms/step - loss: 0.0417\n",
      "processing subset: 1,8\n",
      "Epoch 1/2\n",
      "394/394 [==============================] - 4s 9ms/step - loss: 0.0523\n",
      "Epoch 2/2\n",
      "394/394 [==============================] - 3s 8ms/step - loss: 0.0451\n",
      "processing subset: 1,9\n",
      "Epoch 1/2\n",
      "397/397 [==============================] - 4s 9ms/step - loss: 0.0500\n",
      "Epoch 2/2\n",
      "397/397 [==============================] - 3s 8ms/step - loss: 0.0422\n",
      "processing subset: 2,3\n",
      "Epoch 1/2\n",
      "378/378 [==============================] - 3s 8ms/step - loss: 0.0699\n",
      "Epoch 2/2\n",
      "378/378 [==============================] - 3s 8ms/step - loss: 0.0677\n",
      "processing subset: 2,4\n",
      "Epoch 1/2\n",
      "369/369 [==============================] - 3s 9ms/step - loss: 0.0685\n",
      "Epoch 2/2\n",
      "369/369 [==============================] - 3s 8ms/step - loss: 0.0661\n",
      "processing subset: 2,5\n",
      "Epoch 1/2\n",
      "356/356 [==============================] - 3s 9ms/step - loss: 0.0722\n",
      "Epoch 2/2\n",
      "356/356 [==============================] - 3s 8ms/step - loss: 0.0699\n",
      "processing subset: 2,6\n",
      "Epoch 1/2\n",
      "372/372 [==============================] - 3s 8ms/step - loss: 0.0676\n",
      "Epoch 2/2\n",
      "372/372 [==============================] - 3s 8ms/step - loss: 0.0653\n",
      "processing subset: 2,7\n",
      "Epoch 1/2\n",
      "382/382 [==============================] - 3s 8ms/step - loss: 0.0679\n",
      "Epoch 2/2\n",
      "382/382 [==============================] - 3s 8ms/step - loss: 0.0645\n",
      "processing subset: 2,8\n",
      "Epoch 1/2\n",
      "370/370 [==============================] - 4s 9ms/step - loss: 0.0690\n",
      "Epoch 2/2\n",
      "370/370 [==============================] - 3s 8ms/step - loss: 0.0667\n",
      "processing subset: 2,9\n",
      "Epoch 1/2\n",
      "373/373 [==============================] - 4s 8ms/step - loss: 0.0675\n",
      "Epoch 2/2\n",
      "373/373 [==============================] - 3s 8ms/step - loss: 0.0647\n",
      "processing subset: 3,4\n",
      "Epoch 1/2\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0664\n",
      "Epoch 2/2\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0641\n",
      "processing subset: 3,5\n",
      "Epoch 1/2\n",
      "361/361 [==============================] - 3s 7ms/step - loss: 0.0648\n",
      "Epoch 2/2\n",
      "361/361 [==============================] - 2s 6ms/step - loss: 0.0625\n",
      "processing subset: 3,6\n",
      "Epoch 1/2\n",
      "377/377 [==============================] - 4s 9ms/step - loss: 0.0681\n",
      "Epoch 2/2\n",
      "377/377 [==============================] - 3s 8ms/step - loss: 0.0659\n",
      "processing subset: 3,7\n",
      "Epoch 1/2\n",
      "388/388 [==============================] - 4s 9ms/step - loss: 0.0639\n",
      "Epoch 2/2\n",
      "388/388 [==============================] - 3s 8ms/step - loss: 0.0599\n",
      "processing subset: 3,8\n",
      "Epoch 1/2\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0647\n",
      "Epoch 2/2\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0624\n",
      "processing subset: 3,9\n",
      "Epoch 1/2\n",
      "378/378 [==============================] - 3s 8ms/step - loss: 0.0634\n",
      "Epoch 2/2\n",
      "378/378 [==============================] - 3s 8ms/step - loss: 0.0609\n",
      "processing subset: 4,5\n",
      "Epoch 1/2\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 0.0646\n",
      "Epoch 2/2\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 0.0621\n",
      "processing subset: 4,6\n",
      "Epoch 1/2\n",
      "368/368 [==============================] - 3s 8ms/step - loss: 0.0623\n",
      "Epoch 2/2\n",
      "368/368 [==============================] - 3s 8ms/step - loss: 0.0599\n",
      "processing subset: 4,7\n",
      "Epoch 1/2\n",
      "379/379 [==============================] - 3s 8ms/step - loss: 0.0578\n",
      "Epoch 2/2\n",
      "379/379 [==============================] - 3s 8ms/step - loss: 0.0552\n",
      "processing subset: 4,8\n",
      "Epoch 1/2\n",
      "366/366 [==============================] - 3s 8ms/step - loss: 0.0640\n",
      "Epoch 2/2\n",
      "366/366 [==============================] - 3s 8ms/step - loss: 0.0617\n",
      "processing subset: 4,9\n",
      "Epoch 1/2\n",
      "369/369 [==============================] - 3s 8ms/step - loss: 0.0555\n",
      "Epoch 2/2\n",
      "369/369 [==============================] - 3s 8ms/step - loss: 0.0529\n",
      "processing subset: 5,6\n",
      "Epoch 1/2\n",
      "355/355 [==============================] - 3s 8ms/step - loss: 0.0667\n",
      "Epoch 2/2\n",
      "355/355 [==============================] - 3s 8ms/step - loss: 0.0643\n",
      "processing subset: 5,7\n",
      "Epoch 1/2\n",
      "366/366 [==============================] - 3s 9ms/step - loss: 0.0630\n",
      "Epoch 2/2\n",
      "366/366 [==============================] - 3s 8ms/step - loss: 0.0603\n",
      "processing subset: 5,8\n",
      "Epoch 1/2\n",
      "353/353 [==============================] - 3s 8ms/step - loss: 0.0654\n",
      "Epoch 2/2\n",
      "353/353 [==============================] - 3s 8ms/step - loss: 0.0630\n",
      "processing subset: 5,9\n",
      "Epoch 1/2\n",
      "356/356 [==============================] - 3s 8ms/step - loss: 0.0621\n",
      "Epoch 2/2\n",
      "356/356 [==============================] - 3s 8ms/step - loss: 0.0596\n",
      "processing subset: 6,7\n",
      "Epoch 1/2\n",
      "381/381 [==============================] - 3s 8ms/step - loss: 0.0642\n",
      "Epoch 2/2\n",
      "381/381 [==============================] - 3s 8ms/step - loss: 0.0618\n",
      "processing subset: 6,8\n",
      "Epoch 1/2\n",
      "368/368 [==============================] - 3s 9ms/step - loss: 0.0663\n",
      "Epoch 2/2\n",
      "368/368 [==============================] - 3s 8ms/step - loss: 0.0640\n",
      "processing subset: 6,9\n",
      "Epoch 1/2\n",
      "371/371 [==============================] - 3s 9ms/step - loss: 0.0620\n",
      "Epoch 2/2\n",
      "371/371 [==============================] - 3s 8ms/step - loss: 0.0596\n",
      "processing subset: 7,8\n",
      "Epoch 1/2\n",
      "379/379 [==============================] - 3s 8ms/step - loss: 0.0629\n",
      "Epoch 2/2\n",
      "379/379 [==============================] - 3s 8ms/step - loss: 0.0600\n",
      "processing subset: 7,9\n",
      "Epoch 1/2\n",
      "382/382 [==============================] - 4s 9ms/step - loss: 0.0541\n",
      "Epoch 2/2\n",
      "382/382 [==============================] - 3s 8ms/step - loss: 0.0514\n",
      "processing subset: 8,9\n",
      "Epoch 1/2\n",
      "369/369 [==============================] - 3s 9ms/step - loss: 0.0611\n",
      "Epoch 2/2\n",
      "369/369 [==============================] - 3s 8ms/step - loss: 0.0587\n"
     ]
    }
   ],
   "source": [
    "preprocessing_name = \"Autoencoder\"\n",
    "\n",
    "os.system(\"rm -rf data/\"+preprocessing_name+\"/*\")\n",
    "\n",
    "for subset in itertools.combinations([i for i in range(10)],2):\n",
    "    #mkdir\n",
    "    subset_name = str(subset).replace(\"(\",\"\").replace(\")\",\"\").replace(\" \",\"\")\n",
    "    \n",
    "    os.mkdir(\"data/{}/{}\".format(preprocessing_name,subset_name))\n",
    "    \n",
    "    #log progress\n",
    "    print(\"processing subset:\",subset_name)\n",
    "\n",
    "    x_train_subset = x_train[(y_train == subset[0]) | (y_train == subset[1])]\n",
    "    y_train_subset = y_train[(y_train == subset[0]) | (y_train == subset[1])]\n",
    "    y_train_subset_binary = np.where(y_train_subset == subset[0], 0, y_train_subset)\n",
    "    y_train_subset_binary = np.where(y_train_subset_binary == subset[1], 1, y_train_subset_binary)\n",
    "\n",
    "    x_test_subset = x_test[(y_test == subset[0]) | (y_test == subset[1])]\n",
    "    y_test_subset = y_test[(y_test == subset[0]) | (y_test == subset[1])]\n",
    "    y_test_subset_binary = np.where(y_test_subset == subset[0], 0, y_test_subset)\n",
    "    y_test_subset_binary = np.where(y_test_subset_binary == subset[1], 1, y_test_subset_binary)\n",
    "\n",
    "    x_train_subset = x_train_subset.reshape(x_train_subset.shape[0],784)\n",
    "    x_test_subset = x_test_subset.reshape(x_test_subset.shape[0],784)\n",
    "\n",
    "    x_train_pre , x_test_pre, hist = pre.Autoencoder(x_train_subset,x_test_subset,outputsize=4,epochs=2)\n",
    "\n",
    "    loss = np.array(hist.history[\"loss\"])\n",
    "\n",
    "    for type, dataset in zip([\"x_train\",\"x_test\",\"y_train\",\"y_test\",\"y_train_binary\",\"y_test_binary\",\"loss\"],\n",
    "    [x_train_pre,x_test_pre,y_train_subset,y_test_subset,y_train_subset_binary,y_test_subset_binary,loss]):\n",
    "\n",
    "        np.save(\"data/\"+preprocessing_name+\"/\"+str(subset_name)+\"/\"+type+\".npy\",dataset)\n",
    "\n",
    "    tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing subset: 0,1\n",
      "processing subset: 0,2\n",
      "processing subset: 0,3\n",
      "processing subset: 0,4\n",
      "processing subset: 0,5\n",
      "processing subset: 0,6\n",
      "processing subset: 0,7\n",
      "processing subset: 0,8\n",
      "processing subset: 0,9\n",
      "processing subset: 1,2\n",
      "processing subset: 1,3\n",
      "processing subset: 1,4\n",
      "processing subset: 1,5\n",
      "processing subset: 1,6\n",
      "processing subset: 1,7\n",
      "processing subset: 1,8\n",
      "processing subset: 1,9\n",
      "processing subset: 2,3\n",
      "processing subset: 2,4\n",
      "processing subset: 2,5\n",
      "processing subset: 2,6\n",
      "processing subset: 2,7\n",
      "processing subset: 2,8\n",
      "processing subset: 2,9\n",
      "processing subset: 3,4\n",
      "processing subset: 3,5\n",
      "processing subset: 3,6\n",
      "processing subset: 3,7\n",
      "processing subset: 3,8\n",
      "processing subset: 3,9\n",
      "processing subset: 4,5\n",
      "processing subset: 4,6\n",
      "processing subset: 4,7\n",
      "processing subset: 4,8\n",
      "processing subset: 4,9\n",
      "processing subset: 5,6\n",
      "processing subset: 5,7\n",
      "processing subset: 5,8\n",
      "processing subset: 5,9\n",
      "processing subset: 6,7\n",
      "processing subset: 6,8\n",
      "processing subset: 6,9\n",
      "processing subset: 7,8\n",
      "processing subset: 7,9\n",
      "processing subset: 8,9\n"
     ]
    }
   ],
   "source": [
    "preprocessing_name = \"PCA\"\n",
    "\n",
    "os.system(\"rm -rf data/\"+preprocessing_name+\"/*\")\n",
    "\n",
    "for subset in itertools.combinations([i for i in range(10)],2):\n",
    "    #mkdir\n",
    "    subset_name = str(subset).replace(\"(\",\"\").replace(\")\",\"\").replace(\" \",\"\")\n",
    "    \n",
    "    os.mkdir(\"data/{}/{}\".format(preprocessing_name,subset_name))\n",
    "    \n",
    "    #log progress\n",
    "    print(\"processing subset:\",subset_name)\n",
    "\n",
    "    x_train_subset = x_train[(y_train == subset[0]) | (y_train == subset[1])]\n",
    "    y_train_subset = y_train[(y_train == subset[0]) | (y_train == subset[1])]\n",
    "    y_train_subset_binary = np.where(y_train_subset == subset[0], 0, y_train_subset)\n",
    "    y_train_subset_binary = np.where(y_train_subset_binary == subset[1], 1, y_train_subset_binary)\n",
    "\n",
    "    x_test_subset = x_test[(y_test == subset[0]) | (y_test == subset[1])]\n",
    "    y_test_subset = y_test[(y_test == subset[0]) | (y_test == subset[1])]\n",
    "    y_test_subset_binary = np.where(y_test_subset == subset[0], 0, y_test_subset)\n",
    "    y_test_subset_binary = np.where(y_test_subset_binary == subset[1], 1, y_test_subset_binary)\n",
    "\n",
    "    x_train_subset = x_train_subset.reshape(x_train_subset.shape[0],784)\n",
    "    x_test_subset = x_test_subset.reshape(x_test_subset.shape[0],784)\n",
    "\n",
    "    x_train_pre , x_test_pre = pre.PCA(x_train_subset,x_test_subset,outputsize=4)\n",
    "\n",
    "    x_train_pre = pre.minmax_scaler(x_train_pre,min=0,max=1)\n",
    "    x_test_pre = pre.minmax_scaler(x_test_pre,min=0,max=1)\n",
    "   \n",
    "\n",
    "    for type, dataset in zip([\"x_train\",\"x_test\",\"y_train\",\"y_test\",\"y_train_binary\",\"y_test_binary\"],\n",
    "    [x_train_pre,x_test_pre,y_train_subset,y_test_subset,y_train_subset_binary,y_test_subset_binary]):\n",
    "        np.save(\"data/\"+preprocessing_name+\"/\"+str(subset_name)+\"/\"+type+\".npy\",dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing subset: 0,1\n",
      "processing subset: 0,2\n",
      "processing subset: 0,3\n",
      "processing subset: 0,4\n",
      "processing subset: 0,5\n",
      "processing subset: 0,6\n",
      "processing subset: 0,7\n",
      "processing subset: 0,8\n",
      "processing subset: 0,9\n",
      "processing subset: 1,2\n",
      "processing subset: 1,3\n",
      "processing subset: 1,4\n",
      "processing subset: 1,5\n",
      "processing subset: 1,6\n",
      "processing subset: 1,7\n",
      "processing subset: 1,8\n",
      "processing subset: 1,9\n",
      "processing subset: 2,3\n",
      "processing subset: 2,4\n",
      "processing subset: 2,5\n",
      "processing subset: 2,6\n",
      "processing subset: 2,7\n",
      "processing subset: 2,8\n",
      "processing subset: 2,9\n",
      "processing subset: 3,4\n",
      "processing subset: 3,5\n",
      "processing subset: 3,6\n",
      "processing subset: 3,7\n",
      "processing subset: 3,8\n",
      "processing subset: 3,9\n",
      "processing subset: 4,5\n",
      "processing subset: 4,6\n",
      "processing subset: 4,7\n",
      "processing subset: 4,8\n",
      "processing subset: 4,9\n",
      "processing subset: 5,6\n",
      "processing subset: 5,7\n",
      "processing subset: 5,8\n",
      "processing subset: 5,9\n",
      "processing subset: 6,7\n",
      "processing subset: 6,8\n",
      "processing subset: 6,9\n",
      "processing subset: 7,8\n",
      "processing subset: 7,9\n",
      "processing subset: 8,9\n"
     ]
    }
   ],
   "source": [
    "preprocessing_name = \"RAW\"\n",
    "\n",
    "os.system(\"rm -rf data/\"+preprocessing_name+\"/*\")\n",
    "\n",
    "for subset in itertools.combinations([i for i in range(10)],2):\n",
    "    #mkdir\n",
    "    subset_name = str(subset).replace(\"(\",\"\").replace(\")\",\"\").replace(\" \",\"\")\n",
    "    \n",
    "    os.mkdir(\"data/{}/{}\".format(preprocessing_name,subset_name))\n",
    "    \n",
    "    #log progress\n",
    "    print(\"processing subset:\",subset_name)\n",
    "\n",
    "    x_train_subset = x_train[(y_train == subset[0]) | (y_train == subset[1])]\n",
    "    y_train_subset = y_train[(y_train == subset[0]) | (y_train == subset[1])]\n",
    "\n",
    "    y_train_subset_binary = np.where(y_train_subset == subset[0], 0, y_train_subset)\n",
    "    y_train_subset_binary = np.where(y_train_subset_binary == subset[1], 1, y_train_subset_binary)\n",
    "\n",
    "    x_test_subset = x_test[(y_test == subset[0]) | (y_test == subset[1])]\n",
    "    y_test_subset = y_test[(y_test == subset[0]) | (y_test == subset[1])]\n",
    "    y_test_subset_binary = np.where(y_test_subset == subset[0], 0, y_test_subset)\n",
    "    y_test_subset_binary = np.where(y_test_subset_binary == subset[1], 1, y_test_subset_binary)\n",
    "\n",
    "    x_train_subset = x_train_subset.reshape(x_train_subset.shape[0],784)\n",
    "    x_test_subset = x_test_subset.reshape(x_test_subset.shape[0],784)\n",
    "\n",
    "    for type, dataset in zip(\n",
    "        [\"x_train\",\"x_test\",\"y_train\",\"y_test\",\"y_train_binary\",\"y_test_binary\"],\n",
    "        [x_train_subset,x_test_subset,y_train_subset,y_test_subset,y_train_subset_binary,y_test_subset_binary]):\n",
    "\n",
    "        np.save(\"data/\"+preprocessing_name+\"/\"+str(subset_name)+\"/\"+type+\".npy\",dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "66fbc7444ff33bf974f21d3d224fe531a78305e3f7b70f0cb67a92233fdb1f5a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('tfm1': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
