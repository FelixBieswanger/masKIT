{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from myutils import Preprocessing as pre\n",
    "from myutils import Datasets as ds\n",
    "from myutils import Helpers \n",
    "from myutils import Complexity_Measures as cm\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "#Magic Command, so changes in myutils module are reloaded\n",
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "%aimport myutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_test, y_test = ds.ALL_NUMBERS()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing subset: 6,9\n",
      "processing subset: 6,9\n",
      "processing subset: 6,9\n",
      "processing subset: 6,9\n",
      "processing subset: 6,9\n",
      "processing subset: 6,9\n",
      "processing subset: 6,9\n",
      "processing subset: 6,9\n",
      "processing subset: 0,1\n",
      "processing subset: 0,1\n",
      "processing subset: 0,1\n",
      "processing subset: 0,1\n",
      "processing subset: 0,1\n",
      "processing subset: 0,1\n",
      "processing subset: 0,1\n",
      "processing subset: 0,1\n",
      "processing subset: 3,5\n",
      "processing subset: 3,5\n",
      "processing subset: 3,5\n",
      "processing subset: 3,5\n",
      "processing subset: 3,5\n",
      "processing subset: 3,5\n",
      "processing subset: 3,5\n",
      "processing subset: 3,5\n",
      "processing subset: 4,9\n",
      "processing subset: 4,9\n",
      "processing subset: 4,9\n",
      "processing subset: 4,9\n",
      "processing subset: 4,9\n",
      "processing subset: 4,9\n",
      "processing subset: 4,9\n",
      "processing subset: 4,9\n",
      "processing subset: 0,9\n",
      "processing subset: 0,9\n",
      "processing subset: 0,9\n",
      "processing subset: 0,9\n",
      "processing subset: 0,9\n",
      "processing subset: 0,9\n",
      "processing subset: 0,9\n",
      "processing subset: 0,9\n"
     ]
    }
   ],
   "source": [
    "preprocessing_name = \"Autoencoder_HowmanyEpochs2\"\n",
    "\n",
    "for subset in [(6,9),(0,1),(3,5),(4,9),(0,9)]:\n",
    "    #mkdir\n",
    "    subset_name = str(subset).replace(\"(\",\"\").replace(\")\",\"\").replace(\" \",\"\")\n",
    "\n",
    "\n",
    "    for epochs in range(1,17,2):\n",
    "        \n",
    "        #log progress\n",
    "        print(\"processing subset:\",subset_name)\n",
    "\n",
    "        x_train_subset = x_train[(y_train == subset[0]) | (y_train == subset[1])]\n",
    "        y_train_subset = y_train[(y_train == subset[0]) | (y_train == subset[1])]\n",
    "        y_train_subset_binary = np.where(y_train_subset == subset[0], 0, y_train_subset)\n",
    "        y_train_subset_binary = np.where(y_train_subset_binary == subset[1], 1, y_train_subset_binary)\n",
    "\n",
    "        x_test_subset = x_test[(y_test == subset[0]) | (y_test == subset[1])]\n",
    "        y_test_subset = y_test[(y_test == subset[0]) | (y_test == subset[1])]\n",
    "        y_test_subset_binary = np.where(y_test_subset == subset[0], 0, y_test_subset)\n",
    "        y_test_subset_binary = np.where(y_test_subset_binary == subset[1], 1, y_test_subset_binary)\n",
    "\n",
    "        x_train_subset = x_train_subset.reshape(x_train_subset.shape[0],784)\n",
    "        x_test_subset = x_test_subset.reshape(x_test_subset.shape[0],784)\n",
    "\n",
    "        x_train_pre , x_test_pre, hist = pre.Autoencoder(x_train_subset,x_test_subset,outputsize=4,epochs=epochs)\n",
    "\n",
    "        for type, dataset in zip([\"x_train\",\"x_test\",\"y_train\",\"y_test\",\"y_train_binary\",\"y_test_binary\",\"hist\"],\n",
    "        [x_train_pre,x_test_pre,y_train_subset,y_test_subset,y_train_subset_binary,y_test_subset_binary,hist]):\n",
    "\n",
    "            Helpers.store(dataset,\"data/{}/{}/{}\".format(preprocessing_name,subset_name,epochs),type)\n",
    "\n",
    "        tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 3, 5, 7, 9, 11, 13]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i in range(1,15,2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "66fbc7444ff33bf974f21d3d224fe531a78305e3f7b70f0cb67a92233fdb1f5a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('tfm1': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
