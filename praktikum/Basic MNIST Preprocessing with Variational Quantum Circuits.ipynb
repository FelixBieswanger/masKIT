{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "from maskit.datasets import load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting seeds for reproducible results\n",
    "np.random.seed(1337)\n",
    "random.seed(1337)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the data\n",
    "\n",
    "Data of interest is MNIST data. As we want to go for reproducible results, we\n",
    "will first go with the option `shuffle=False`. For the rest of the parameters,\n",
    "we now go with the default options. This gives us data for two classes, the\n",
    "written numbers 6 and 9. We also only get a limited number of sampes, that is\n",
    "100 samples for training and 50 for testing. For further details see the\n",
    "appropriate docstring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-28 20:01:26.522031: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "data = load_data(\"mnist\", shuffle=False, target_length=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up a Variational Quantum Circuit for training\n",
    "\n",
    "There is an example on the [PennyLane website](https://pennylane.ai/qml/demos/tutorial_variational_classifier.html#iris-classification) for iris data showing a setup for a variational classifier. That is variational quantum circuits that can be trained from labelled (classical) data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "wires = 4\n",
    "layers = 4\n",
    "epochs = 5\n",
    "parameters = np.random.uniform(low=-np.pi, high=np.pi, size=(layers, wires, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def variational_circuit(params):\n",
    "    for layer in range(layers):\n",
    "        for wire in range(wires):\n",
    "            qml.RX(params[layer][wire][0], wires=wire)\n",
    "            qml.RY(params[layer][wire][1], wires=wire)\n",
    "        for wire in range(0, wires - 1, 2):\n",
    "            qml.CZ(wires=[wire, wire + 1])\n",
    "        for wire in range(1, wires - 1, 2):\n",
    "            qml.CZ(wires=[wire, wire + 1])\n",
    "    return qml.expval(qml.PauliZ(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def variational_training_circuit(params, data):\n",
    "    qml.templates.embeddings.AngleEmbedding(\n",
    "        features=data, wires=range(wires), rotation=\"X\"\n",
    "    )\n",
    "    return variational_circuit(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = qml.device('default.qubit', wires=wires, shots=1000)\n",
    "circuit = qml.QNode(func=variational_circuit, device=dev)\n",
    "training_circuit = qml.QNode(func=variational_training_circuit, device=dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.052, requires_grad=True)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "circuit(parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.014, requires_grad=True)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_circuit(parameters, data.train_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0: ──RX(0.105)──RX(-1.5)───RY(-2.14)───╭C───RX(1.46)────RY(-2.42)──────────────╭C───RX(1.85)───RY(-0.872)─────────────╭C───RX(-0.00221)──RY(-2.02)──────────────╭C──────┤ ⟨Z⟩ \n",
      " 1: ──RX(2.88)───RX(-1.39)──RY(-0.256)──╰Z──╭C───────────RX(-0.715)──RY(0.807)──╰Z──╭C──────────RX(-0.527)──RY(0.529)──╰Z──╭C─────────────RX(-0.546)──RY(-1.89)──╰Z──╭C──┤     \n",
      " 2: ──RX(1.85)───RX(-1.12)──RY(0.116)───╭C──╰Z───────────RX(-2.36)───RY(3.04)───╭C──╰Z──────────RX(1.63)────RY(-1.96)──╭C──╰Z─────────────RX(0.199)───RY(2.09)───╭C──╰Z──┤     \n",
      " 3: ──RX(0.862)──RX(-1.5)───RY(2.99)────╰Z───RX(-0.357)──RY(1.82)───────────────╰Z───RX(-1.33)──RY(1.07)───────────────╰Z───RX(-1.98)─────RY(2.87)───────────────╰Z──────┤     \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(training_circuit.draw())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some helpers\n",
    "def correctly_classified(params, data, target):\n",
    "    prediction = training_circuit(params, data)\n",
    "    if prediction < 0 and target[0] > 0:\n",
    "        return True\n",
    "    elif prediction > 0 and target[1] > 0:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def overall_cost_and_correct(cost_fn, params, data, targets):\n",
    "    cost = correct_count = 0\n",
    "    for datum, target in zip(data, targets):\n",
    "        cost += cost_fn(params, datum, target)\n",
    "        correct_count += int(correctly_classified(params, datum, target))\n",
    "    return cost, correct_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Playing with different cost functions\n",
    "def crossentropy_cost(params, data, target):\n",
    "    prediction = training_circuit(params, data)\n",
    "    scaled_prediction = prediction + 1 / 2\n",
    "    predictions = np.array([1 - scaled_prediction, scaled_prediction])\n",
    "    return cross_entropy(predictions, target)\n",
    "\n",
    "def distributed_cost(params, data, target):\n",
    "    \"\"\"Cost function distributes probabilities to both classes.\"\"\"\n",
    "    prediction = training_circuit(params, data)\n",
    "    scaled_prediction = prediction + 1 / 2\n",
    "    predictions = np.array([1 - scaled_prediction, scaled_prediction])\n",
    "    return np.sum(np.abs(target - predictions))\n",
    "\n",
    "def cost(params, data, target):\n",
    "    \"\"\"Cost function penalizes choosing wrong class.\"\"\"\n",
    "    prediction = training_circuit(params, data)\n",
    "    predictions = np.array([0, prediction]) if prediction > 0 else np.array([prediction * -1, 0])\n",
    "    return np.sum(np.abs(target - predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = qml.AdamOptimizer()\n",
    "cost_fn = cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start cost: 56.230000000000004, with 24/50 correct samples\n"
     ]
    }
   ],
   "source": [
    "start_cost, correct_count = overall_cost_and_correct(cost_fn, parameters, data.test_data, data.test_target)\n",
    "print(f\"start cost: {start_cost}, with {correct_count}/{len(data.test_target)} correct samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = parameters.copy()\n",
    "for _ in range(epochs):\n",
    "    for datum, target in zip(data.train_data, data.train_target):\n",
    "        params = optimizer.step(lambda weights: cost_fn(weights, datum, target), params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final cost: 31.440000000000005, with 39/50 correct samples\n"
     ]
    }
   ],
   "source": [
    "final_cost, correct_count = overall_cost_and_correct(cost_fn, params, data.test_data, data.test_target)\n",
    "print(f\"final cost: {final_cost}, with {correct_count}/{len(data.test_target)} correct samples\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "88e75e00cca6104550b192c3a69472ab1bd4ad5bb62fbc08ff10d3358391bfd4"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('venv': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
