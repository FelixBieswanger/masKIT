{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from myutils import Preprocessing as pre\n",
    "from myutils import Datasets as ds\n",
    "from myutils import Helpers \n",
    "from myutils import Complexity_Measures as cm\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "#Magic Command, so changes in myutils module are reloaded\n",
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "%aimport myutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_test, y_test = ds.ALL_NUMBERS()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AutoEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing subset: 6,9 and outputsize 13\n",
      "Epoch 1/50\n",
      "371/371 [==============================] - 3s 6ms/step - loss: 0.1192\n",
      "Epoch 2/50\n",
      "371/371 [==============================] - 2s 6ms/step - loss: 0.1120\n",
      "Epoch 3/50\n",
      "371/371 [==============================] - 2s 6ms/step - loss: 0.1047\n",
      "Epoch 4/50\n",
      "371/371 [==============================] - 2s 6ms/step - loss: 0.0982\n",
      "Epoch 5/50\n",
      "371/371 [==============================] - 2s 6ms/step - loss: 0.0957\n",
      "Epoch 6/50\n",
      "371/371 [==============================] - 2s 6ms/step - loss: 0.0946\n",
      "Epoch 7/50\n",
      "371/371 [==============================] - 2s 6ms/step - loss: 0.0941\n",
      "Epoch 8/50\n",
      "371/371 [==============================] - 2s 6ms/step - loss: 0.0935\n",
      "Epoch 9/50\n",
      "371/371 [==============================] - 2s 6ms/step - loss: 0.0930\n",
      "Epoch 10/50\n",
      "371/371 [==============================] - 2s 6ms/step - loss: 0.0924\n",
      "Epoch 11/50\n",
      "371/371 [==============================] - 2s 5ms/step - loss: 0.0918\n",
      "Epoch 12/50\n",
      "371/371 [==============================] - 2s 6ms/step - loss: 0.0911\n",
      "Epoch 13/50\n",
      "371/371 [==============================] - 2s 6ms/step - loss: 0.0903\n",
      "Epoch 14/50\n",
      "371/371 [==============================] - 2s 6ms/step - loss: 0.0895\n",
      "Epoch 15/50\n",
      "371/371 [==============================] - 2s 6ms/step - loss: 0.0887\n",
      "Epoch 16/50\n",
      "371/371 [==============================] - 2s 6ms/step - loss: 0.0883\n",
      "Epoch 17/50\n",
      "371/371 [==============================] - 2s 6ms/step - loss: 0.0877\n",
      "Epoch 18/50\n",
      "371/371 [==============================] - 2s 6ms/step - loss: 0.0871\n",
      "Epoch 19/50\n",
      "371/371 [==============================] - 2s 6ms/step - loss: 0.0864\n",
      "Epoch 20/50\n",
      "371/371 [==============================] - 2s 6ms/step - loss: 0.0859\n",
      "Epoch 21/50\n",
      "371/371 [==============================] - 2s 6ms/step - loss: 0.0856\n",
      "Epoch 22/50\n",
      "371/371 [==============================] - 2s 5ms/step - loss: 0.0852\n",
      "Epoch 23/50\n",
      "371/371 [==============================] - 2s 6ms/step - loss: 0.0847\n",
      "Epoch 24/50\n",
      "371/371 [==============================] - 2s 6ms/step - loss: 0.0842\n",
      "Epoch 25/50\n",
      "371/371 [==============================] - 2s 6ms/step - loss: 0.0839\n",
      "Epoch 26/50\n",
      "371/371 [==============================] - 2s 6ms/step - loss: 0.0837\n",
      "Epoch 27/50\n",
      "371/371 [==============================] - 2s 6ms/step - loss: 0.0835\n",
      "Epoch 28/50\n",
      "371/371 [==============================] - 2s 6ms/step - loss: 0.0833\n",
      "Epoch 29/50\n",
      "371/371 [==============================] - 2s 6ms/step - loss: 0.0831\n",
      "Epoch 30/50\n",
      "371/371 [==============================] - 2s 6ms/step - loss: 0.0828\n",
      "Epoch 31/50\n",
      "371/371 [==============================] - 2s 6ms/step - loss: 0.0826\n",
      "Epoch 32/50\n",
      "371/371 [==============================] - 2s 6ms/step - loss: 0.0824\n",
      "Epoch 33/50\n",
      "371/371 [==============================] - 2s 6ms/step - loss: 0.0822\n",
      "Epoch 34/50\n",
      "371/371 [==============================] - 2s 6ms/step - loss: 0.0819\n",
      "Epoch 35/50\n",
      "371/371 [==============================] - 2s 6ms/step - loss: 0.0816\n",
      "Epoch 36/50\n",
      "371/371 [==============================] - 2s 6ms/step - loss: 0.0814\n",
      "Epoch 37/50\n",
      "371/371 [==============================] - 2s 6ms/step - loss: 0.0812\n",
      "Epoch 38/50\n",
      "371/371 [==============================] - 2s 6ms/step - loss: 0.0810\n",
      "Epoch 39/50\n",
      "371/371 [==============================] - 2s 6ms/step - loss: 0.0806\n",
      "Epoch 40/50\n",
      "371/371 [==============================] - 2s 6ms/step - loss: 0.0803\n",
      "Epoch 41/50\n",
      "371/371 [==============================] - 2s 6ms/step - loss: 0.0801\n",
      "Epoch 42/50\n",
      "371/371 [==============================] - 2s 6ms/step - loss: 0.0797\n",
      "Epoch 43/50\n",
      "371/371 [==============================] - 2s 6ms/step - loss: 0.0791\n",
      "Epoch 44/50\n",
      "371/371 [==============================] - 2s 6ms/step - loss: 0.0789\n",
      "Epoch 45/50\n",
      "371/371 [==============================] - 2s 6ms/step - loss: 0.0787\n",
      "Epoch 46/50\n",
      "371/371 [==============================] - 2s 6ms/step - loss: 0.0785\n",
      "Epoch 47/50\n",
      "371/371 [==============================] - 2s 6ms/step - loss: 0.0783\n",
      "Epoch 48/50\n",
      "371/371 [==============================] - 2s 6ms/step - loss: 0.0781\n",
      "Epoch 49/50\n",
      "371/371 [==============================] - 2s 6ms/step - loss: 0.0780\n",
      "Epoch 50/50\n",
      "371/371 [==============================] - 2s 6ms/step - loss: 0.0778\n"
     ]
    }
   ],
   "source": [
    "preprocessing_name = \"Autoencoder\"\n",
    "\n",
    "for subset in [(6,9)]:\n",
    "\n",
    "    for outputsize in [13]:\n",
    "\n",
    "        subset_name = str(subset).replace(\"(\",\"\").replace(\")\",\"\").replace(\" \",\"\")\n",
    "            \n",
    "        #log progress\n",
    "        print(\"processing subset: {} and outputsize {}\".format(subset_name,outputsize))\n",
    "        os.makedirs(\"data/increasingFeature/{}/{}/{}\".format(preprocessing_name,subset_name,outputsize),exist_ok=True)\n",
    "\n",
    "        x_train_subset = x_train[(y_train == subset[0]) | (y_train == subset[1])]\n",
    "        y_train_subset = y_train[(y_train == subset[0]) | (y_train == subset[1])]\n",
    "        y_train_subset_binary = np.where(y_train_subset == subset[0], 0, y_train_subset)\n",
    "        y_train_subset_binary = np.where(y_train_subset_binary == subset[1], 1, y_train_subset_binary)\n",
    "\n",
    "        x_test_subset = x_test[(y_test == subset[0]) | (y_test == subset[1])]\n",
    "        y_test_subset = y_test[(y_test == subset[0]) | (y_test == subset[1])]\n",
    "        y_test_subset_binary = np.where(y_test_subset == subset[0], 0, y_test_subset)\n",
    "        y_test_subset_binary = np.where(y_test_subset_binary == subset[1], 1, y_test_subset_binary)\n",
    "\n",
    "        x_train_subset = x_train_subset.reshape(x_train_subset.shape[0],784)\n",
    "        x_test_subset = x_test_subset.reshape(x_test_subset.shape[0],784)\n",
    "\n",
    "        x_train_pre , x_test_pre, hist = pre.Autoencoder(x_train_subset,x_test_subset,outputsize=outputsize,epochs=50,verbose=1)\n",
    "\n",
    "        for type, dataset in zip([\"x_train\",\"x_test\",\"y_train\",\"y_test\",\"y_train_binary\",\"y_test_binary\",\"hist\"],\n",
    "        [x_train_pre,x_test_pre,y_train_subset,y_test_subset,y_train_subset_binary,y_test_subset_binary,hist]):\n",
    "\n",
    "\n",
    "            Helpers.store(dataset,\"data/increasingFeature/{}/{}/{}\".format(preprocessing_name,outputsize,subset_name),type)\n",
    "\n",
    "        tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing subset: 6,9 and outputsize 5\n",
      "processing subset: 6,9 and outputsize 7\n",
      "processing subset: 6,9 and outputsize 9\n",
      "processing subset: 6,9 and outputsize 11\n",
      "processing subset: 6,9 and outputsize 13\n"
     ]
    }
   ],
   "source": [
    "preprocessing_name = \"PCA\"\n",
    "\n",
    "for subset in [(6,9)]:\n",
    "\n",
    "    for outputsize in range(5,14,2):\n",
    "\n",
    "        #mkdir\n",
    "        subset_name = str(subset).replace(\"(\",\"\").replace(\")\",\"\").replace(\" \",\"\")\n",
    "        \n",
    "        \n",
    "        #log progress\n",
    "        print(\"processing subset: {} and outputsize {}\".format(subset_name,outputsize))\n",
    "\n",
    "        x_train_subset = x_train[(y_train == subset[0]) | (y_train == subset[1])]\n",
    "        y_train_subset = y_train[(y_train == subset[0]) | (y_train == subset[1])]\n",
    "        y_train_subset_binary = np.where(y_train_subset == subset[0], 0, y_train_subset)\n",
    "        y_train_subset_binary = np.where(y_train_subset_binary == subset[1], 1, y_train_subset_binary)\n",
    "\n",
    "        x_test_subset = x_test[(y_test == subset[0]) | (y_test == subset[1])]\n",
    "        y_test_subset = y_test[(y_test == subset[0]) | (y_test == subset[1])]\n",
    "        y_test_subset_binary = np.where(y_test_subset == subset[0], 0, y_test_subset)\n",
    "        y_test_subset_binary = np.where(y_test_subset_binary == subset[1], 1, y_test_subset_binary)\n",
    "\n",
    "        x_train_subset = x_train_subset.reshape(x_train_subset.shape[0],784)\n",
    "        x_test_subset = x_test_subset.reshape(x_test_subset.shape[0],784)\n",
    "\n",
    "        x_train_pre , x_test_pre = pre.PCA(x_train_subset,x_test_subset,outputsize=outputsize)\n",
    "\n",
    "        x_train_pre = pre.minmax_scaler(x_train_pre,min=0,max=1)\n",
    "        x_test_pre = pre.minmax_scaler(x_test_pre,min=0,max=1)\n",
    "    \n",
    "\n",
    "        for type, dataset in zip([\"x_train\",\"x_test\",\"y_train\",\"y_test\",\"y_train_binary\",\"y_test_binary\"],\n",
    "        [x_train_pre,x_test_pre,y_train_subset,y_test_subset,y_train_subset_binary,y_test_subset_binary]):\n",
    "            Helpers.store(dataset,\"data/increasingFeature/{}/{}/{}\".format(preprocessing_name,outputsize,subset_name),type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing subset: 0,1\n",
      "processing subset: 0,2\n",
      "processing subset: 0,3\n",
      "processing subset: 0,4\n",
      "processing subset: 0,5\n",
      "processing subset: 0,6\n",
      "processing subset: 0,7\n",
      "processing subset: 0,8\n",
      "processing subset: 0,9\n",
      "processing subset: 1,2\n",
      "processing subset: 1,3\n",
      "processing subset: 1,4\n",
      "processing subset: 1,5\n",
      "processing subset: 1,6\n",
      "processing subset: 1,7\n",
      "processing subset: 1,8\n",
      "processing subset: 1,9\n",
      "processing subset: 2,3\n",
      "processing subset: 2,4\n",
      "processing subset: 2,5\n",
      "processing subset: 2,6\n",
      "processing subset: 2,7\n",
      "processing subset: 2,8\n",
      "processing subset: 2,9\n",
      "processing subset: 3,4\n",
      "processing subset: 3,5\n",
      "processing subset: 3,6\n",
      "processing subset: 3,7\n",
      "processing subset: 3,8\n",
      "processing subset: 3,9\n",
      "processing subset: 4,5\n",
      "processing subset: 4,6\n",
      "processing subset: 4,7\n",
      "processing subset: 4,8\n",
      "processing subset: 4,9\n",
      "processing subset: 5,6\n",
      "processing subset: 5,7\n",
      "processing subset: 5,8\n",
      "processing subset: 5,9\n",
      "processing subset: 6,7\n",
      "processing subset: 6,8\n",
      "processing subset: 6,9\n",
      "processing subset: 7,8\n",
      "processing subset: 7,9\n",
      "processing subset: 8,9\n"
     ]
    }
   ],
   "source": [
    "preprocessing_name = \"RAW\"\n",
    "\n",
    "os.system(\"rm -rf data/\"+preprocessing_name+\"/*\")\n",
    "\n",
    "for subset in itertools.combinations([i for i in range(10)],2):\n",
    "    #mkdir\n",
    "    subset_name = str(subset).replace(\"(\",\"\").replace(\")\",\"\").replace(\" \",\"\")\n",
    "    \n",
    "    os.makedirs(\"data/{}/{}\".format(preprocessing_name,subset_name))\n",
    "    \n",
    "    #log progress\n",
    "    print(\"processing subset:\",subset_name)\n",
    "\n",
    "    x_train_subset = x_train[(y_train == subset[0]) | (y_train == subset[1])]\n",
    "    y_train_subset = y_train[(y_train == subset[0]) | (y_train == subset[1])]\n",
    "\n",
    "    y_train_subset_binary = np.where(y_train_subset == subset[0], 0, y_train_subset)\n",
    "    y_train_subset_binary = np.where(y_train_subset_binary == subset[1], 1, y_train_subset_binary)\n",
    "\n",
    "    x_test_subset = x_test[(y_test == subset[0]) | (y_test == subset[1])]\n",
    "    y_test_subset = y_test[(y_test == subset[0]) | (y_test == subset[1])]\n",
    "    y_test_subset_binary = np.where(y_test_subset == subset[0], 0, y_test_subset)\n",
    "    y_test_subset_binary = np.where(y_test_subset_binary == subset[1], 1, y_test_subset_binary)\n",
    "\n",
    "    x_train_subset = x_train_subset.reshape(x_train_subset.shape[0],784)\n",
    "    x_test_subset = x_test_subset.reshape(x_test_subset.shape[0],784)\n",
    "\n",
    "    for type, dataset in zip(\n",
    "        [\"x_train\",\"x_test\",\"y_train\",\"y_test\",\"y_train_binary\",\"y_test_binary\"],\n",
    "        [x_train_subset,x_test_subset,y_train_subset,y_test_subset,y_train_subset_binary,y_test_subset_binary]):\n",
    "\n",
    "        np.save(\"data/\"+preprocessing_name+\"/\"+str(subset_name)+\"/\"+type+\".npy\",dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_test, y_test = ds.ALL_NUMBERS()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing subset: 0,6\n"
     ]
    }
   ],
   "source": [
    "subset_name = \"0,6\"\n",
    "subset = (0,6)\n",
    "preprocessing_name =\"Autoencoder_small\" \n",
    "\n",
    "#log progress\n",
    "print(\"processing subset:\",subset_name)\n",
    "\n",
    "x_train_subset = x_train[(y_train == subset[0]) | (y_train == subset[1])]\n",
    "y_train_subset = y_train[(y_train == subset[0]) | (y_train == subset[1])]\n",
    "y_train_subset_binary = np.where(y_train_subset == subset[0], 0, y_train_subset)\n",
    "y_train_subset_binary = np.where(y_train_subset_binary == subset[1], 1, y_train_subset_binary)\n",
    "\n",
    "x_test_subset = x_test[(y_test == subset[0]) | (y_test == subset[1])]\n",
    "y_test_subset = y_test[(y_test == subset[0]) | (y_test == subset[1])]\n",
    "y_test_subset_binary = np.where(y_test_subset == subset[0], 0, y_test_subset)\n",
    "y_test_subset_binary = np.where(y_test_subset_binary == subset[1], 1, y_test_subset_binary)\n",
    "\n",
    "x_train_subset = x_train_subset.reshape(x_train_subset.shape[0],784)\n",
    "x_test_subset = x_test_subset.reshape(x_test_subset.shape[0],784)\n",
    "\n",
    "x_train_pre , x_test_pre, hist = pre.Autoencoder(x_train_subset,x_test_subset,outputsize=4,epochs=15)\n",
    "\n",
    "for type, dataset in zip([\"x_train\",\"x_test\",\"y_train\",\"y_test\",\"y_train_binary\",\"y_test_binary\",\"hist\"],\n",
    "[x_train_pre,x_test_pre,y_train_subset,y_test_subset,y_train_subset_binary,y_test_subset_binary,hist]):\n",
    "\n",
    "\n",
    "    Helpers.store(dataset,\"data/{}/{}\".format(preprocessing_name,subset_name),type)\n",
    "\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x576 with 42 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = ds.get_preprocessed_datasets(\"Autoencoder_small\")[\"Autoencoder_small\"][\"0,6\"]\n",
    "Helpers.plot_grid(data[\"x_train\"],data[\"y_train\"],rows=7,cols=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "66fbc7444ff33bf974f21d3d224fe531a78305e3f7b70f0cb67a92233fdb1f5a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('tfm1': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
